

âœ… Yes â€” 100% possible, and exactly how OutbreakIQ is designed to work.

You can absolutely make your pipeline handle many diseases (Cholera, Measles, Lassa Fever, Yellow Fever, etc.) â€” and in fact, your current code is already multi-disease capable.
You just need to supply the missing links (the extra NCDC disease data + the WHO mapping file).

Letâ€™s break this down step-by-step so you can see how it works and how to activate it ğŸ‘‡

ğŸ§© HOW MULTI-DISEASE SUPPORT WORKS

Your system joins data from multiple sources on these keys:

(state, disease, year, week)


So as long as you:

Have multiple diseases in your NCDC file (ncdc_outbreaks_clean.csv), and

The WHO indicators for those diseases are mapped in who_indicator_mapping.csv,

then the build process automatically merges and trains models for each one.

âš™ï¸ HOW TO DO IT (step-by-step)
ğŸ§¾ Step 1: Expand Your NCDC Data

Right now your ncdc_outbreaks_clean.csv only has COVID-19 rows.
You can add more diseases like this:

state	disease	year	week	cases	deaths
Lagos	Cholera	2024	12	20	0
Kano	Measles	2024	18	42	0
Edo	Lassa Fever	2024	4	9	1
Sokoto	Meningitis	2024	10	15	2
Cross River	Yellow Fever	2024	15	11	0

Save these new rows into data/ncdc_outbreaks_clean.csv.
You can even append them directly in Excel or Python.
Once this file has multiple diseases, everything downstream handles them separately.

ğŸŒ Step 2: Map WHO Indicators to Your Diseases

Open:

data/raw/who_indicator_mapping.csv


Each row looks like this:

disease_label	indicator_code	canonical_disease
Cholera - number of reported cases	WHS3_35	Cholera
Measles - number of reported cases	WHS3_40	Measles
Cerebrospinal meningitis - number of reported cases	WHS3_38	Meningitis
Yellow fever - number of reported cases	WHS3_59	Yellow Fever
Lassa fever cases	WHS_LASSA01	Lassa Fever
Rubella - number of reported cases	WHS3_50	Rubella
Japanese encephalitis - number of reported cases	WHS3_42	Japanese Encephalitis

Anything with a valid canonical_disease value will merge automatically with your NCDC dataset during feature building.

(You can fill this file in Excel or Notepad â€” itâ€™s simple CSV.)

âš™ï¸ Step 3: Rebuild Features

Run:

python build_features.py


Your log will now show something like:

[SAVED] data/outbreakiq_training_data_filled.csv rows=3124 cols=20
[SUMMARY] Total NCDC cases by disease (top 10):
disease
Covid-19        3024
Cholera         546
Lassa Fever     312
Measles         880
Meningitis      223
Yellow Fever    116
Name: cases, dtype: int64


âœ… That means your WHO + NCDC + weather + population data all merged correctly across diseases.

ğŸ§  Step 4: Retrain Models

Run your normal ML steps again:

python -m ml.train_regression
python -m ml.train_alert
python -m ml.eval_models
python -m live_data.run_live_cycle --mode realtime


The outputs will now contain metrics per disease:

metrics_regression.csv

disease	mae	overall_mae
Covid-19	5.6	5.6
Cholera	2.8	5.6
Lassa Fever	3.1	5.6
Measles	1.9	5.6

metrics_alert_classification.csv

disease	precision	recall	f1
Covid-19	0.73	0.83	0.78
Cholera	0.81	0.79	0.80
Lassa Fever	0.77	0.85	0.81
âœ… Step 5: Realtime Predictions for All Diseases

When you run:

python -m live_data.run_live_cycle --mode realtime


the output file will now have predictions like this:

reports/production/predictions_live.csv

state	disease	year	week	predicted_cases
Lagos	Cholera	2025	47	23
Edo	Lassa Fever	2025	47	12
Kano	Measles	2025	47	41
Abuja	Covid-19	2025	47	131
ğŸ’¡ Summary: What Makes It Possible
Component	Multi-Disease Capable?	Why
Data ingestion	âœ…	Reads and normalizes any disease label
WHO mapping	âœ…	You define canonical_disease mappings
Feature builder	âœ…	Groups by (state, disease, year, week)
Model training	âœ…	Automatically trains per-disease
Evaluation & drift	âœ…	Computes per-disease metrics
Live cycle	âœ…	Predicts per-disease per-state

Your code is already architected for multi-disease forecasting â€”
you just need to feed it multi-disease data and finish the WHO mappings.

If youâ€™d like, I can:

ğŸ” Inspect your current who_disease_data.csv and who_indicator_mapping.csv
and automatically generate a ready-to-fill template of all unmapped diseases
(so you can quickly complete the mapping file and unlock all WHO signals).
ğŸ”¥ Perfect â€” this is a great next step for OutbreakIQ.
Adding deep learning (especially an LSTM forecaster) will let your system capture temporal dependencies and nonlinear outbreak patterns that the regression models canâ€™t.

Letâ€™s build this properly, step-by-step. ğŸ‘‡

ğŸ§  Goal

Create a new deep learning module:

ml/train_deep.py


that:

Loads your merged training dataset (data/outbreakiq_training_data_filled.csv)

Creates sequential (8-week) samples per (state, disease)

Trains an LSTM model to predict cases_next_week

Saves the trained model at models/lstm_forecaster.h5

âš™ï¸ 1ï¸âƒ£ Directory Check

Make sure your folder structure includes:

project_root/
â”‚
â”œâ”€â”€ data/outbreakiq_training_data_filled.csv
â”œâ”€â”€ ml/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ utils.py
â”‚   â”œâ”€â”€ train_regression.py
â”‚   â”œâ”€â”€ train_alert.py
â”‚   â””â”€â”€ train_deep.py   ğŸ‘ˆ (weâ€™ll create this)
â””â”€â”€ models/

ğŸ’» 2ï¸âƒ£ Install Dependencies

Run this once:

pip install tensorflow scikit-learn numpy pandas

ğŸ§© 3ï¸âƒ£ Create ml/train_deep.py

Hereâ€™s the full, ready-to-use script:

import os
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.models import save_model

DATA_PATH = "data/outbreakiq_training_data_filled.csv"
MODEL_PATH = "models/lstm_forecaster.h5"

def make_sequences(df, window=8):
    """Generate sequence samples (X, y) for each (state, disease)."""
    features = ["cases", "temperature_2m_mean", "relative_humidity_2m_mean", "precipitation_sum"]
    X, y = [], []

    for (disease, state), g in df.groupby(["disease", "state"]):
        g = g.sort_values(["year", "week"])
        vals = g[features].fillna(0).values
        for i in range(window, len(vals)):
            X.append(vals[i-window:i])
            y.append(vals[i, 0])  # next weekâ€™s cases
    return np.array(X), np.array(y)

def main():
    print("=== Training LSTM Deep Model ===")

    if not os.path.exists(DATA_PATH):
        raise FileNotFoundError(f"{DATA_PATH} not found!")

    df = pd.read_csv(DATA_PATH)
    print(f"[INFO] Loaded dataset: {df.shape[0]} rows, {df.shape[1]} cols")

    # Scale continuous variables
    scaler = MinMaxScaler()
    df[["cases", "temperature_2m_mean", "relative_humidity_2m_mean", "precipitation_sum"]] = \
        scaler.fit_transform(df[["cases", "temperature_2m_mean", "relative_humidity_2m_mean", "precipitation_sum"]])

    X, y = make_sequences(df, window=8)
    print(f"[INFO] Generated {len(X)} sequences of shape {X.shape[1:]}")

    model = Sequential([
        LSTM(64, input_shape=(X.shape[1], X.shape[2]), return_sequences=False),
        Dropout(0.3),
        Dense(32, activation='relu'),
        Dense(1)
    ])
    model.compile(optimizer='adam', loss='mae')
    model.summary()

    es = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

    history = model.fit(
        X, y,
        validation_split=0.1,
        epochs=100,
        batch_size=32,
        callbacks=[es],
        verbose=1
    )

    os.makedirs(os.path.dirname(MODEL_PATH), exist_ok=True)
    model.save(MODEL_PATH)
    print(f"âœ… Model trained and saved as {MODEL_PATH}")

if __name__ == "__main__":
    main()

ğŸš€ 4ï¸âƒ£ Run Training

Once the file is saved, just run:

python -m ml.train_deep


You should see:

=== Training LSTM Deep Model ===
[INFO] Loaded dataset: 401 rows, 20 cols
[INFO] Generated 300 sequences of shape (8, 4)
Epoch 1/100 ...
...
âœ… Model trained and saved as models/lstm_forecaster.h5

ğŸ”® 5ï¸âƒ£ Next: Use It for Live Prediction

When the model is saved, modify live_data/run_live_cycle.py (or create ml/predict_deep.py) to load it:

from tensorflow.keras.models import load_model
import numpy as np

model = load_model("models/lstm_forecaster.h5")

# last 8 weeks of Lagos COVID data
latest_window = np.expand_dims(your_feature_array[-8:], axis=0)
predicted = model.predict(latest_window)
print("Predicted next-week cases:", predicted)

ğŸ“ˆ Optional Improvements Later
Feature	Description
ğŸ§® Multi-week forecast (Seq2Seq)	Predict multiple weeks at once
ğŸ§  Temporal Fusion Transformer (TFT)	For advanced multi-feature forecasting
âš¡ Auto hyperparameter tuning	Use KerasTuner for different window/neurons
ğŸŒ Disease-specific models	Train separate LSTMs per disease type
ğŸ¤ Hybrid ensemble	Combine regression + LSTM predictions
âœ… Summary

You now have a full deep learning training pipeline for OutbreakIQ:

Sequential input generation

LSTM forecasting

Model persistence (models/lstm_forecaster.h5)

Reusable integration with your live prediction pipeline